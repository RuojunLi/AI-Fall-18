{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import os\n",
    "import math\n",
    "from sklearn.metrics import f1_score\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "#####################\n",
    "#Auther: Ruojun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Raw Data(Using in the promblem 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file_save(file_name):\n",
    "    if not os.path.isfile('train.txt'):\n",
    "        ####################\n",
    "        #load file\n",
    "        file = open(file_name)\n",
    "        file_data = file.readlines()\n",
    "        features = file_data[28:53]\n",
    "        data = [line.strip().split(',') for line in file_data[145:545]]\n",
    "        data.remove(data[369])\n",
    "        dataframe = sklearn.utils.shuffle(pd.DataFrame(data))\n",
    "        dataframe.drop(columns=25)\n",
    "        ########################\n",
    "        #drop missing data\n",
    "        debug1 = dataframe == '?'\n",
    "        drop_result = dataframe[debug1.sum(1) == 0]\n",
    "        drop_result[24] = drop_result[24].map({'notckd': 0, 'ckd': 1})\n",
    "        drop_result[5] = drop_result[5].map({'normal': 0, 'abnormal': 1})\n",
    "        drop_result[6] = drop_result[6].map({'normal': 0, 'abnormal': 1})\n",
    "        drop_result[7] = drop_result[7].map({'present': 0, 'notpresent': 1})\n",
    "        drop_result[8] = drop_result[8].map({'present': 0, 'notpresent': 1})\n",
    "        drop_result[18] = drop_result[18].map({'no': 0, 'yes': 1})\n",
    "        drop_result[19] = drop_result[19].map({'no': 0, 'yes': 1})\n",
    "        drop_result[20] = drop_result[20].map({'no': 0, 'yes': 1})\n",
    "        drop_result[21] = drop_result[21].map({'poor': 0, 'good': 1})\n",
    "        drop_result[22] = drop_result[22].map({'no': 0, 'yes': 1})\n",
    "        drop_result[23] = drop_result[23].map({'no': 0, 'yes': 1})\n",
    "        ########################\n",
    "        #Split train and test\n",
    "        train_data = drop_result[0:int(len(drop_result)*0.8)]\n",
    "        test_data = drop_result[int(len(drop_result)*0.8):]\n",
    "        train_data.to_csv('train.txt',header=False,index=False)\n",
    "        test_data.to_csv('test.txt',header=False,index=False)\n",
    "    train_x = np.asarray(pd.read_csv('train.txt', header=None))[:, 0:23]\n",
    "    test_x = np.asarray(pd.read_csv('test.txt', header=None))[:, 0:23]\n",
    "    train_y = np.asarray(pd.read_csv('train.txt', header=None))[:, 24]\n",
    "    test_y = np.asarray(pd.read_csv('test.txt', header=None))[:, 24]\n",
    "    return train_x,train_y,test_x,test_y\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_measure(y_hat,y):\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "    for i in range(np.size(y)):\n",
    "        if np.allclose(y[i], 0., atol=1e-3)&np.allclose(y_hat[i], 0.,atol=1e-3):TP +=1\n",
    "        elif np.allclose(y[i], 0., atol=1e-3) & np.allclose(y_hat[i], 1., atol=1e-3): FP += 1\n",
    "        elif np.allclose(y[i], 1., atol=1e-3) & np.allclose(y_hat[i], 0., atol=1e-3): FN += 1\n",
    "    PRE = TP/(TP+FP)\n",
    "    REC = TP/(TP+FN)\n",
    "    f_measure = (2*PRE*REC)/(PRE+REC)\n",
    "    return f_measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'chronic_kidney_disease_full.arff'\n",
    "train_x,train_y,test_x,test_y = load_file_save(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1 = SVC(kernel='linear')\n",
    "clf1.fit(train_x, train_y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction: [1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      " 0. 1. 0. 1. 0. 0. 0. 0.]\n",
      "true label: [1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      " 0. 1. 0. 1. 0. 0. 0. 0.]\n",
      "f-measure: 0.9803921568627451\n"
     ]
    }
   ],
   "source": [
    "test_predict1 = clf1.predict(test_x).reshape(np.shape(test_y))\n",
    "print(\"prediction:\",test_predict1)\n",
    "print(\"true label:\",test_y)\n",
    "f1_score = f_measure(test_predict1,test_y)\n",
    "print(\"f-measure:\",f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2 = SVC(kernel='rbf')\n",
    "clf2.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "true label: [1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      " 0. 1. 0. 1. 0. 0. 0. 0.]\n",
      "f-measure: 0.8771929824561403\n"
     ]
    }
   ],
   "source": [
    "test_predict2 = clf2.predict(test_x).reshape(np.shape(test_y))\n",
    "train_predict2 = clf2.predict(train_x)\n",
    "print(\"prediction:\",test_predict2)\n",
    "print(\"true label:\",test_y)\n",
    "f1_score = f_measure(test_predict2,test_y)\n",
    "print(\"f-measure:\",f1_score)\n",
    "print(\"Train f-measure:\",f_measure(train_predict2,train_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction: [1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      " 0. 1. 0. 1. 0. 0. 0. 0.]\n",
      "true label: [1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      " 0. 1. 0. 1. 0. 0. 0. 0.]\n",
      "Test f-measure: 1.0\n",
      "Test f-measure: 1.0\n"
     ]
    }
   ],
   "source": [
    "clf3 = RandomForestClassifier(n_estimators=100, max_depth=2,\n",
    "                              random_state=0)\n",
    "clf3.fit(train_x, train_y)\n",
    "test_predict3 = clf3.predict(test_x)\n",
    "train_predict3 = clf3.predict(train_x)\n",
    "print(\"prediction:\",test_predict3)\n",
    "print(\"true label:\",test_y)\n",
    "f1_score = f_measure(test_predict3,test_y)\n",
    "print(\"Test f-measure:\",f1_score)\n",
    "print(\"Train f-measure:\",f_measure(train_predict3,train_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
