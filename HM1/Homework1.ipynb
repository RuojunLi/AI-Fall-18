{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import collections\n",
    "\n",
    "    \n",
    "def SRAP():\n",
    "    \"\"\"This agent takes action based solely on the percept\"\"\"\n",
    "    def program(percept):\n",
    "        loc, status = percept\n",
    "        return ('Suck' if status == 'Dirty'\n",
    "                else 'Right' if loc == loc_A else 'Left')\n",
    "    return program\n",
    "def homework(default_env,default_agent,is_print=False):\n",
    "    #Only two squares in the vaccum environment\n",
    "    loc_A = (0, 0)\n",
    "    loc_B = (1, 0)\n",
    "    loc_dict = loc_A, loc_B\n",
    "    \n",
    "    # Agent\n",
    "    simple_agent = Agent(SRAP())\n",
    "    \n",
    "    # Initialize the two-state environment\n",
    "    trivial_vacuum_env = TrivialVacuumEnvironment()\n",
    "    trivial_vacuum_env.status = default_env\n",
    "    print(\"Default State of the Environment: {}.\".format(trivial_vacuum_env.status))\n",
    "    trivial_vacuum_env.add_thing(simple_agent)\n",
    "    simple_agent.location = default_agent\n",
    "    print(\"Default SimpleReflexVacuumAgent is located at {}.\".format(simple_agent.location))\n",
    "    awards = 0\n",
    "\n",
    "    for i in range(1000):\n",
    "        for loc in loc_dict:\n",
    "            if trivial_vacuum_env.status[loc] == 'Clean': awards += 1\n",
    "        # Run\n",
    "        trivial_vacuum_env.step()\n",
    "        # Print the current state of the environment\n",
    "        if is_print == True:\n",
    "            print(\"Time step: {}\".format(i+1))\n",
    "            print(\"State of the Environment: {}.\".format(trivial_vacuum_env.status))\n",
    "            print(\"SimpleReflexVacuumAgent is located at {}.\".format(simple_agent.location))\n",
    "    print(\"performance score is \" + str(awards))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Thing:\n",
    "    \"\"\"This represents any physical object that can appear in an Environment.\n",
    "    You subclass Thing to get the things you want. Each thing can have a\n",
    "    .__name__  slot (used for output only).\"\"\"\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '<{}>'.format(getattr(self, '__name__', self.__class__.__name__))\n",
    "\n",
    "    def is_alive(self):\n",
    "        \"\"\"Things that are 'alive' should return true.\"\"\"\n",
    "        return hasattr(self, 'alive') and self.alive\n",
    "\n",
    "    def show_state(self):\n",
    "        \"\"\"Display the agent's internal state. Subclasses should override.\"\"\"\n",
    "        print(\"I don't know how to show_state.\")\n",
    "\n",
    "    def display(self, canvas, x, y, width, height):\n",
    "        \"\"\"Display an image of this Thing on the canvas.\"\"\"\n",
    "        # Do we need this?\n",
    "        pass\n",
    "\n",
    "\n",
    "class Agent(Thing):\n",
    "    \"\"\"An Agent is a subclass of Thing with one required slot,\n",
    "    .program, which should hold a function that takes one argument, the\n",
    "    percept, and returns an action. (What counts as a percept or action\n",
    "    will depend on the specific environment in which the agent exists.)\n",
    "    Note that 'program' is a slot, not a method. If it were a method,\n",
    "    then the program could 'cheat' and look at aspects of the agent.\n",
    "    It's not supposed to do that: the program can only look at the\n",
    "    percepts. An agent program that needs a model of the world (and of\n",
    "    the agent itself) will have to build and maintain its own model.\n",
    "    There is an optional slot, .performance, which is a number giving\n",
    "    the performance measure of the agent in its environment.\"\"\"\n",
    "\n",
    "    def __init__(self, program=None):\n",
    "        self.alive = True\n",
    "        self.bump = False\n",
    "        self.holding = []\n",
    "        self.performance = 0\n",
    "        if program is None or not isinstance(program, collections.Callable):\n",
    "            print(\"Can't find a valid program for {}, falling back to default.\".format(\n",
    "                self.__class__.__name__))\n",
    "\n",
    "            def program(percept):\n",
    "                return eval(input('Percept={}; action? '.format(percept)))\n",
    "\n",
    "        self.program = program\n",
    "\n",
    "    def can_grab(self, thing):\n",
    "        \"\"\"Return True if this agent can grab this thing.\n",
    "        Override for appropriate subclasses of Agent and Thing.\"\"\"\n",
    "        return False\n",
    "\n",
    "# ______________________________________________________________________________\n",
    "\n",
    "\n",
    "loc_A, loc_B = (0, 0), (1, 0)  # The two locations for the Vacuum world\n",
    "\n",
    "class Environment:\n",
    "    \"\"\"Abstract class representing an Environment. 'Real' Environment classes\n",
    "    inherit from this. Your Environment will typically need to implement:\n",
    "        percept:           Define the percept that an agent sees.\n",
    "        execute_action:    Define the effects of executing an action.\n",
    "                           Also update the agent.performance slot.\n",
    "    The environment keeps a list of .things and .agents (which is a subset\n",
    "    of .things). Each agent has a .performance slot, initialized to 0.\n",
    "    Each thing has a .location slot, even though some environments may not\n",
    "    need this.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.things = []\n",
    "        self.agents = []\n",
    "\n",
    "    def thing_classes(self):\n",
    "        return []  # List of classes that can go into environment\n",
    "\n",
    "    def percept(self, agent):\n",
    "        \"\"\"Return the percept that the agent sees at this point. (Implement this.)\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def execute_action(self, agent, action):\n",
    "        \"\"\"Change the world to reflect this action. (Implement this.)\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def default_location(self, thing):\n",
    "        \"\"\"Default location to place a new thing with unspecified location.\"\"\"\n",
    "        return None\n",
    "\n",
    "    def exogenous_change(self):\n",
    "        \"\"\"If there is spontaneous change in the world, override this.\"\"\"\n",
    "        pass\n",
    "\n",
    "    def is_done(self):\n",
    "        \"\"\"By default, we're done when we can't find a live agent.\"\"\"\n",
    "        return not any(agent.is_alive() for agent in self.agents)\n",
    "\n",
    "    def step(self):\n",
    "        \"\"\"Run the environment for one time step. If the\n",
    "        actions and exogenous changes are independent, this method will\n",
    "        do. If there are interactions between them, you'll need to\n",
    "        override this method.\"\"\"\n",
    "        if not self.is_done():\n",
    "            actions = []\n",
    "            for agent in self.agents:\n",
    "                if agent.alive:\n",
    "                    actions.append(agent.program(self.percept(agent)))\n",
    "                else:\n",
    "                    actions.append(\"\")\n",
    "            for (agent, action) in zip(self.agents, actions):\n",
    "                self.execute_action(agent, action)\n",
    "            self.exogenous_change()\n",
    "\n",
    "    def run(self, steps=1000):\n",
    "        \"\"\"Run the Environment for given number of time steps.\"\"\"\n",
    "        for step in range(steps):\n",
    "            if self.is_done():\n",
    "                return\n",
    "            self.step()\n",
    "\n",
    "\n",
    "    def add_thing(self, thing, location=None):\n",
    "        \"\"\"Add a thing to the environment, setting its location. For\n",
    "        convenience, if thing is an agent program we make a new agent\n",
    "        for it. (Shouldn't need to override this.)\"\"\"\n",
    "        if not isinstance(thing, Thing):\n",
    "            thing = Agent(thing)\n",
    "        if thing in self.things:\n",
    "            print(\"Can't add the same thing twice\")\n",
    "        else:\n",
    "            thing.location = location if location is not None else self.default_location(thing)\n",
    "            self.things.append(thing)\n",
    "            if isinstance(thing, Agent):\n",
    "                thing.performance = 0\n",
    "                self.agents.append(thing)\n",
    "\n",
    "    def delete_thing(self, thing):\n",
    "        \"\"\"Remove a thing from the environment.\"\"\"\n",
    "        try:\n",
    "            self.things.remove(thing)\n",
    "        except ValueError as e:\n",
    "            print(e)\n",
    "            print(\"  in Environment delete_thing\")\n",
    "            print(\"  Thing to be removed: {} at {}\".format(thing, thing.location))\n",
    "            print(\"  from list: {}\".format([(thing, thing.location) for thing in self.things]))\n",
    "        if thing in self.agents:\n",
    "            self.agents.remove(thing)\n",
    "            \n",
    "class TrivialVacuumEnvironment(Environment):\n",
    "    \"\"\"This environment has two locations, A and B. Each can be Dirty\n",
    "    or Clean. The agent perceives its location and the location's\n",
    "    status. This serves as an example of how to implement a simple\n",
    "    Environment.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.status = {loc_A: 'Dirty', loc_B: 'Dirty'}\n",
    "        self.default_agent = loc_B\n",
    "    def percept(self, agent):\n",
    "        \"\"\"Returns the agent's location, and the location status (Dirty/Clean).\"\"\"\n",
    "        return (agent.location, self.status[agent.location])\n",
    "\n",
    "    def execute_action(self, agent, action):\n",
    "        \"\"\"Change agent's location and/or location's status; track performance.\n",
    "        Score 10 for each dirt cleaned; -1 for each move.\"\"\"\n",
    "        if action == 'Right':\n",
    "            agent.location = loc_B\n",
    "        elif action == 'Left':\n",
    "            agent.location = loc_A\n",
    "        elif action == 'Suck':\n",
    "            if self.status[agent.location] == 'Dirty':\n",
    "                self.status[agent.location] = 'Clean'\n",
    "\n",
    "    def default_location(self, thing):\n",
    "        return self.default_agent\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default State of the Environment: {(0, 0): 'Dirty', (1, 0): 'Dirty'}.\n",
      "Default SimpleReflexVacuumAgent is located at (0, 0).\n",
      "performance score is 1996\n"
     ]
    }
   ],
   "source": [
    "loc_A = (0, 0)\n",
    "loc_B = (1, 0)\n",
    "env_df = {loc_A: 'Dirty', loc_B: 'Dirty'}\n",
    "agent_df = loc_A\n",
    "homework(env_df,agent_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default State of the Environment: {(0, 0): 'Dirty', (1, 0): 'Dirty'}.\n",
      "Default SimpleReflexVacuumAgent is located at (1, 0).\n",
      "performance score is 1996\n"
     ]
    }
   ],
   "source": [
    "env_df = {loc_A: 'Dirty', loc_B: 'Dirty'}\n",
    "agent_df = loc_B\n",
    "homework(env_df,agent_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default State of the Environment: {(0, 0): 'Dirty', (1, 0): 'Clean'}.\n",
      "Default SimpleReflexVacuumAgent is located at (0, 0).\n",
      "performance score is 1999\n"
     ]
    }
   ],
   "source": [
    "env_df = {loc_A: 'Dirty', loc_B: 'Clean'}\n",
    "agent_df = loc_A\n",
    "homework(env_df,agent_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default State of the Environment: {(0, 0): 'Dirty', (1, 0): 'Clean'}.\n",
      "Default SimpleReflexVacuumAgent is located at (1, 0).\n",
      "performance score is 1998\n"
     ]
    }
   ],
   "source": [
    "env_df = {loc_A: 'Dirty', loc_B: 'Clean'}\n",
    "agent_df = loc_B\n",
    "homework(env_df,agent_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default State of the Environment: {(0, 0): 'Clean', (1, 0): 'Dirty'}.\n",
      "Default SimpleReflexVacuumAgent is located at (0, 0).\n",
      "performance score is 1998\n"
     ]
    }
   ],
   "source": [
    "env_df = {loc_A: 'Clean', loc_B: 'Dirty'}\n",
    "agent_df = loc_A\n",
    "homework(env_df,agent_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default State of the Environment: {(0, 0): 'Clean', (1, 0): 'Dirty'}.\n",
      "Default SimpleReflexVacuumAgent is located at (1, 0).\n",
      "performance score is 1999\n"
     ]
    }
   ],
   "source": [
    "env_df = {loc_A: 'Clean', loc_B: 'Dirty'}\n",
    "agent_df = loc_B\n",
    "homework(env_df,agent_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default State of the Environment: {(0, 0): 'Clean', (1, 0): 'Clean'}.\n",
      "Default SimpleReflexVacuumAgent is located at (0, 0).\n",
      "performance score is 2000\n"
     ]
    }
   ],
   "source": [
    "env_df = {loc_A: 'Clean', loc_B: 'Clean'}\n",
    "agent_df = loc_A\n",
    "homework(env_df,agent_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default State of the Environment: {(0, 0): 'Clean', (1, 0): 'Clean'}.\n",
      "Default SimpleReflexVacuumAgent is located at (1, 0).\n",
      "performance score is 2000\n"
     ]
    }
   ],
   "source": [
    "env_df = {loc_A: 'Clean', loc_B: 'Clean'}\n",
    "agent_df = loc_B\n",
    "homework(env_df,agent_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
